---
layout: distill
title: "Explore the Score Distillation Sampling technique"
description:
tags: iclr2023 diffusion-model score-distillation
categories: review
giscus_comments: false
date: 2024-06-21
featured: false
mermaid:
  enabled: true
  zoomable: true
code_diff: true
map: true
chart:
  chartjs: true
  echarts: true
  vega_lite: true
tikzjax: true
typograms: true

bibliography: 2018-12-22-distill.bib
---

In this post, I will delve into Score Distillation Sampling (SDS), the core method powering [DreamFusion](https://arxiv.org/abs/2209.14988)

<div class="row">
  <div class="mx-auto col-sm mt-3 mt-md-0">
      {% include figure.liquid path="assets/img/sds/dreamfusion.png" class="img-fluid rounded z-depth-1" zoomable=true %}
  </div>
</div>
<div class="caption">
  DreamFusion training diagram. The image is from DreamFusion paper.
</div>
   
---

DreamFusion is a text-to-3D synthesis pipeline that optimizes a Neural Radiance Field (NeRF) to align with a given text prompt. The synthesis procedure in DreamFusion is as follows:

1. Randomly initialized NeRF from scratch
2. Randomly sample a camera and light
3. Using a differentiable render to render an image of the NeRF from that camera and shade with the light
4. Compute gradient of the SDS loss w.r.t the NeRF params
5. Update NeRF params and repeat from step 2

At the core of DreamFusion lies the SDS loss, which we will explore.

### My SDS interpretation

From my perspective, the SDS loss shares some similarities with the discriminator loss in GANs, as it evaluates the fidelity of an input image. However, unlike GANs where the discriminator is trained concurrently with the generator, SDS utilizes a pre-trained, frozen diffusion model as its discriminator.

Assuming $\mathbf{x}=g_\theta (y)$ is the image generated by a generator $g$ parameterized by $\theta$ and $y$ is the input prompt, our objective is to optimize $\theta$ such that $\mathbf{x}$ looks like a sample $x_0 \sim p_0(x \vert y)$ implicitly defined by the frozen diffusion model. This objective means the diffusion loss given $x$ as the clean signal must be small. Specifically, we optimize:

$$
\theta^*=\min_\theta \mathcal{L}_\mathrm{Diff}(\phi,\mathbf{x}=g_\theta(y))
$$

where $\phi$ is params of the pretrained frozen diffusion model and

$$
\mathcal{L}_\mathrm{Diff}(\phi,\mathbf{x})=\mathbb{E}_{t,\epsilon} ||
w(t)(\hat\epsilon_\phi(\mathbf{z}_t;y,t)-\epsilon)
||^2_2
$$

$$
\mathbf{z}_t=\sqrt{\bar\alpha_t}\mathbf{x} + \sqrt{1-\bar\alpha_t}\epsilon
$$

Note that here I assume we are using DDPM $\epsilon$-prediction type model.

<div class="row">
  <div class="mx-auto col-sm mt-3 mt-md-0">
      {% include figure.liquid path="assets/img/sds/train.png" class="img-fluid rounded z-depth-1" zoomable=true %}
  </div>
</div>

### SDS Loss

In practice, it turn outs that the above loss doesnâ€™t work well to produce realistic samples because computation of gradient of $\mathcal{L}_\mathrm{Diff}$ is unstable.

If we break down gradient of $\mathcal{L}_\mathrm{Diff}$, we have

<div class="row">
  <div class="mx-auto col-sm mt-3 mt-md-0">
      {% include figure.liquid path="assets/img/sds/gradient_eqt.png" class="img-fluid rounded z-depth-1" zoomable=true %}
  </div>
</div>

The authors of DreamFusion propose to omit the U-Net Jacobian terms because:

- It is expensive to compute
- It is poorly conditioned for small noise levels

which results in $\theta$ being updated by the following gradient:

<div class="row">
  <div class="mx-auto col-sm-9 mt-3 mt-md-0">
      {% include figure.liquid path="assets/img/sds/sds_formula.png" class="img-fluid rounded z-depth-1" zoomable=true %}
  </div>
</div>

This formula is more concise and efficient since we no longer need to backpropagate through the diffusion network.

### Implementation

There are two ways to update $\theta$ at each optimizing step:

1. Directly compute $\nabla_\theta \mathcal{L}_\mathrm{SDS}$ via the above formula and use the result to update $\theta$
2. Make pytorch and optimizer compute the gradient and update $\theta$. In order to do it, we have to find a $ \mathcal{L}\_\mathrm{SDS} $ satisfying $\nabla_\theta \mathcal{L}\_\mathrm{SDS}$, which is as simple as

$$
\mathcal{L}_\mathrm{SDS}=\mathbb{E}_{t,\epsilon} \left[
w(t) (\hat\epsilon_\phi(\mathbf{z};y,t)-\epsilon) \mathbf{x}
\right]
$$

### Limitations

SDS has issues of mode collapse that generates non-diverse and blurry outputs that only highlight elements mentioned in the prompt, as shown in the image below.

<div class="row">
  <div class="mx-auto col-sm mt-3 mt-md-0">
      {% include figure.liquid path="assets/img/sds/limitation.png" class="img-fluid rounded z-depth-1" zoomable=true %}
  </div>
</div>
